# NLP/BERT/Transformer Repository

This directory contains example code for the the BERT sentiment analysis model demonstrated in presentation.

## BERT:
Tensorflow framework implemented by the Google's Research team. It contains implementations of state-of-the-art BERT algorithm for NLP tasks:
https://github.com/google-research/bert

A forked copy is available here: https://github.com/ecbme6040/bert

### sentiment_analysis_with_bert.ipynb: 
Jupyter notebook by Curiosily of using BERT via the Hugging Face Transformers library. This tutorial illustrates an example of utilizing a pretrained BERT model for sentiment analysis with google play store reviews.

## Questions?

For any questions, please feel free to contact Emile Chamoun (ec3478@columbia.edu), Bryant Zhang (bhz2103@columbia.edu), Isabella Smythe (iss2118@columbia.edu).

## References

[1] Devlin, Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina (11 October 2018). "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding". arXiv:1810.04805v2

[2] Alammar, Jay. “The Illustrated BERT, ELMo, and co.”

[3] Khalid, Samia. “BERT Explained: A Complete Guide with Theory and Tutorial”

[4] Horev, Rani. “BERT Explained: State of the Art Laguage Model for NLP”

[5] Rivki, Mohd Sanad Zaki. “Demystifying BERT: A Comprehensive Guide to the Groundbreaking NLP Framework” 

[6] "Sentiment Analysis with BERT and Transformers by Hugging Face using PyTorch and Python", https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/
