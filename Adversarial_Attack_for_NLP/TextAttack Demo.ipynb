{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textattack in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.2.15)\n",
      "Requirement already satisfied: scipy==1.4.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (1.4.1)\n",
      "Requirement already satisfied: word2number in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (1.1)\n",
      "Requirement already satisfied: lru-dict in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (1.1.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (1.7.1)\n",
      "Requirement already satisfied: editdistance in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (0.5.3)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (1.7.1)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (4.49.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (3.0.12)\n",
      "Requirement already satisfied: lemminflect in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (0.2.2)\n",
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (1.5.0)\n",
      "Requirement already satisfied: numpy<1.19.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (1.18.5)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (1.0.5)\n",
      "Requirement already satisfied: transformers>=3.3.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (4.4.2)\n",
      "Requirement already satisfied: terminaltables in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (3.1.0)\n",
      "Requirement already satisfied: bert-score>=0.3.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (0.3.8)\n",
      "Requirement already satisfied: flair==0.6.1.post1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (0.6.1.post1)\n",
      "Requirement already satisfied: num2words in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (0.5.10)\n",
      "Requirement already satisfied: more-itertools in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (8.7.0)\n",
      "Requirement already satisfied: language-tool-python in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (2.5.3)\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from textattack) (3.5)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torch->textattack) (3.7.4.3)\n",
      "Requirement already satisfied: dill in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets->textattack) (0.3.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets->textattack) (2.24.0)\n",
      "Requirement already satisfied: multiprocess in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets->textattack) (0.70.11.1)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets->textattack) (0.8.7)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets->textattack) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets->textattack) (0.0.7)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets->textattack) (2.0.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas>=1.0.1->textattack) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas>=1.0.1->textattack) (2.8.1)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from transformers>=3.3.0->textattack) (20.4)\n",
      "Requirement already satisfied: sacremoses in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from transformers>=3.3.0->textattack) (0.0.43)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from transformers>=3.3.0->textattack) (0.10.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from transformers>=3.3.0->textattack) (2021.3.17)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from bert-score>=0.3.5->textattack) (3.3.2)\n",
      "Requirement already satisfied: hyperopt>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (0.2.5)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (1.2.12)\n",
      "Requirement already satisfied: tabulate in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (0.8.9)\n",
      "Requirement already satisfied: segtok>=1.5.7 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (1.5.10)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (0.1.95)\n",
      "Requirement already satisfied: janome in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (0.4.1)\n",
      "Requirement already satisfied: langdetect in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (1.0.8)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (3.8.3)\n",
      "Requirement already satisfied: bpemb>=0.3.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (0.3.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (0.23.1)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (1.7.0)\n",
      "Requirement already satisfied: gdown in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (3.12.2)\n",
      "Requirement already satisfied: lxml in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (4.6.3)\n",
      "Requirement already satisfied: ftfy in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (5.9)\n",
      "Requirement already satisfied: mpld3==0.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (0.3)\n",
      "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from flair==0.6.1.post1->textattack) (4.6.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docopt>=0.6.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from num2words->textattack) (0.6.2)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk->textattack) (0.15.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk->textattack) (7.1.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.19.0->datasets->textattack) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.19.0->datasets->textattack) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.19.0->datasets->textattack) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.19.0->datasets->textattack) (2020.6.20)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tongxue/Library/Python/3.8/lib/python/site-packages (from python-dateutil>=2.6.1->pandas>=1.0.1->textattack) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from packaging->transformers>=3.3.0->textattack) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (7.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.2.0)\n",
      "Requirement already satisfied: cloudpickle in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from hyperopt>=0.1.1->flair==0.6.1.post1->textattack) (1.6.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from hyperopt>=0.1.1->flair==0.6.1.post1->textattack) (2.5)\n",
      "Requirement already satisfied: future in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from hyperopt>=0.1.1->flair==0.6.1.post1->textattack) (0.18.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/tongxue/Library/Python/3.8/lib/python/site-packages (from deprecated>=1.2.4->flair==0.6.1.post1->textattack) (1.12.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from gensim>=3.4.0->flair==0.6.1.post1->textattack) (4.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn>=0.21.3->flair==0.6.1.post1->textattack) (2.1.0)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from ftfy->flair==0.6.1.post1->textattack) (0.2.5)\n",
      "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from konoha<5.0.0,>=4.0.0->flair==0.6.1.post1->textattack) (3.1.0)\n",
      "Requirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from konoha<5.0.0,>=4.0.0->flair==0.6.1.post1->textattack) (3.7.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from networkx>=2.2->hyperopt>=0.1.1->flair==0.6.1.post1->textattack) (4.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair==0.6.1.post1->textattack) (3.4.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install textattack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Downloading tensorflow_hub-0.11.0-py2.py3-none-any.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow_hub) (1.18.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow_hub) (3.12.2)\n",
      "Requirement already satisfied: six>=1.9 in /Users/tongxue/Library/Python/3.8/lib/python/site-packages (from protobuf>=3.8.0->tensorflow_hub) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from protobuf>=3.8.0->tensorflow_hub) (47.1.0)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.11.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textattack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/tongxue/.cache/huggingface/datasets/glue/sst2/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94msst2\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
      "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/albert-base-v2-SST-2\u001b[0m\n",
      "Using /var/folders/fw/w0fpl04j2bq447h1j1_kywj40000gn/T/tfhub_modules to cache modules.\n",
      "Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/4'.\n",
      "Downloading https://tfhub.dev/google/universal-sentence-encoder/4: 80.00MB\n",
      "Downloading https://tfhub.dev/google/universal-sentence-encoder/4: 180.00MB\n",
      "Downloading https://tfhub.dev/google/universal-sentence-encoder/4: 280.00MB\n",
      "Downloading https://tfhub.dev/google/universal-sentence-encoder/4: 380.00MB\n",
      "Downloading https://tfhub.dev/google/universal-sentence-encoder/4: 500.00MB\n",
      "Downloading https://tfhub.dev/google/universal-sentence-encoder/4: 610.00MB\n",
      "Downloading https://tfhub.dev/google/universal-sentence-encoder/4: 720.00MB\n",
      "Downloading https://tfhub.dev/google/universal-sentence-encoder/4: 810.00MB\n",
      "Downloading https://tfhub.dev/google/universal-sentence-encoder/4: 900.00MB\n",
      "Downloading https://tfhub.dev/google/universal-sentence-encoder/4: 979.63MB\n",
      "Downloaded https://tfhub.dev/google/universal-sentence-encoder/4, Total size: 987.47MB\n",
      "Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/4'.\n",
      "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.albert.modeling_albert.AlbertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (min_cos_sim):  0.5\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): PartOfSpeech(\n",
      "        (tagger_type):  nltk\n",
      "        (tagset):  universal\n",
      "        (allow_verb_noun_swap):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (2): UniversalSentenceEncoder(\n",
      "        (metric):  angular\n",
      "        (threshold):  0.840845057\n",
      "        (window_size):  15\n",
      "        (skip_text_shorter_than_window):  True\n",
      "        (compare_against_original):  False\n",
      "      )\n",
      "    (3): RepeatModification\n",
      "    (4): StopwordModification\n",
      "    (5): InputColumnModification(\n",
      "        (matching_column_labels):  ['premise', 'hypothesis']\n",
      "        (columns_to_ignore):  {'premise'}\n",
      "      )\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n",
      "\u001b[34;1mtextattack\u001b[0m: Load time: 183.99869680404663s\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]--------------------------------------------- Result 1 ---------------------------------------------\n",
      "\u001b[91mNegative (99%)\u001b[0m --> \u001b[92mPositive (58%)\u001b[0m\n",
      "\n",
      "the most \u001b[91mhopelessly\u001b[0m \u001b[91mmonotonous\u001b[0m film of the year , noteworthy only for the \u001b[91mgimmick\u001b[0m of being filmed as a single unbroken 87-minute take . \n",
      "\n",
      "the most \u001b[92mlethally\u001b[0m \u001b[92mhumdrum\u001b[0m film of the year , noteworthy only for the \u001b[92mthing\u001b[0m of being filmed as a single unbroken 87-minute take . \n",
      "\n",
      "\n",
      "[Succeeded / Failed / Total] 1 / 0 / 1:  10%|▍   | 1/10 [00:46<06:54, 46.00s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
      "\u001b[91mNegative (99%)\u001b[0m --> \u001b[92mPositive (65%)\u001b[0m\n",
      "\n",
      "as a rumor of angels reveals itself to be a sudsy tub of supernatural \u001b[91mhokum\u001b[0m , not even \u001b[91mms\u001b[0m. redgrave 's noblest efforts can redeem it from hopeless sentimentality . \n",
      "\n",
      "as a rumor of angels reveals itself to be a sudsy tub of supernatural \u001b[92msentimentalism\u001b[0m , not even \u001b[92mmonica\u001b[0m. redgrave 's noblest efforts can redeem it from hopeless sentimentality . \n",
      "\n",
      "\n",
      "[Succeeded / Failed / Total] 2 / 0 / 2:  20%|▊   | 2/10 [01:56<07:44, 58.11s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
      "\u001b[92mPositive (93%)\u001b[0m --> \u001b[91mNegative (55%)\u001b[0m\n",
      "\n",
      "bennett 's naturalistic performance \u001b[92mspeaks\u001b[0m volumes more truth than any ` reality ' show , and anybody contemplating their own drastic life changes should watch some body first . \n",
      "\n",
      "bennett 's naturalistic performance \u001b[91mschmooze\u001b[0m volumes more truth than any ` reality ' show , and anybody contemplating their own drastic life changes should watch some body first . \n",
      "\n",
      "\n",
      "[Succeeded / Failed / Total] 3 / 0 / 3:  30%|█▏  | 3/10 [02:40<06:14, 53.54s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
      "\u001b[91mNegative (58%)\u001b[0m --> \u001b[92mPositive (65%)\u001b[0m\n",
      "\n",
      "by getting myself wrapped up in the visuals and eccentricities of many of the characters , i found myself \u001b[91mconfused\u001b[0m when it came time to get to the heart of the movie . \n",
      "\n",
      "by getting myself wrapped up in the visuals and eccentricities of many of the characters , i found myself \u001b[92mconfusion\u001b[0m when it came time to get to the heart of the movie . \n",
      "\n",
      "\n",
      "[Succeeded / Failed / Total] 4 / 0 / 4:  40%|█▌  | 4/10 [03:14<04:52, 48.73s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
      "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (61%)\u001b[0m\n",
      "\n",
      "anchored by friel and williams 's \u001b[92mexceptional\u001b[0m performances , the film 's \u001b[92mpower\u001b[0m lies in its complexity . \n",
      "\n",
      "anchored by friel and williams 's \u001b[91munbelievable\u001b[0m performances , the film 's \u001b[91mjurisdiction\u001b[0m lies in its complexity . \n",
      "\n",
      "\n",
      "[Succeeded / Failed / Total] 5 / 0 / 5:  50%|██  | 5/10 [04:05<04:05, 49.19s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
      "\u001b[92mPositive (96%)\u001b[0m --> \u001b[91mNegative (93%)\u001b[0m\n",
      "\n",
      "a \u001b[92mwoman\u001b[0m 's pic directed with \u001b[92mresonance\u001b[0m by \u001b[92milya\u001b[0m chaiken . \n",
      "\n",
      "a \u001b[91mmissus\u001b[0m 's pic directed with \u001b[91mharmonics\u001b[0m by \u001b[91milyas\u001b[0m chaiken . \n",
      "\n",
      "\n",
      "[Succeeded / Failed / Total] 6 / 0 / 6:  60%|██▍ | 6/10 [04:35<03:03, 45.98s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
      "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (76%)\u001b[0m\n",
      "\n",
      "the \u001b[92mbest\u001b[0m film about \u001b[92mbaseball\u001b[0m to hit theaters since field of dreams . \n",
      "\n",
      "the \u001b[91mstrictest\u001b[0m film about \u001b[91mslug\u001b[0m to hit theaters since field of dreams . \n",
      "\n",
      "\n",
      "[Succeeded / Failed / Total] 7 / 0 / 7:  70%|██▊ | 7/10 [05:16<02:15, 45.16s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
      "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (54%)\u001b[0m\n",
      "\n",
      "too \u001b[91mrestrained\u001b[0m to \u001b[91mbe\u001b[0m a freak \u001b[91mshow\u001b[0m , too \u001b[91mmercenary\u001b[0m and \u001b[91mobvious\u001b[0m to \u001b[91mbe\u001b[0m \u001b[91mcerebral\u001b[0m , too \u001b[91mdull\u001b[0m and \u001b[91mpretentious\u001b[0m to \u001b[91mbe\u001b[0m \u001b[91mengaging\u001b[0m ... the \u001b[91misle\u001b[0m defies an \u001b[91measy\u001b[0m categorization . \n",
      "\n",
      "too \u001b[92mrestricting\u001b[0m to \u001b[92mrepresent\u001b[0m a freak \u001b[92mdemonstrates\u001b[0m , too \u001b[92menforcer\u001b[0m and \u001b[92mnoteworthy\u001b[0m to \u001b[92mexists\u001b[0m \u001b[92mskull\u001b[0m , too \u001b[92msomber\u001b[0m and \u001b[92msassy\u001b[0m to \u001b[92mcome\u001b[0m \u001b[92mmobilise\u001b[0m ... the \u001b[92mislands\u001b[0m defies an \u001b[92mreadily\u001b[0m categorization . \n",
      "\n",
      "\n",
      "[Succeeded / Failed / Total] 8 / 0 / 8:  80%|███▏| 8/10 [09:30<02:22, 71.26s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
      "\u001b[91mNegative (99%)\u001b[0m --> \u001b[92mPositive (80%)\u001b[0m\n",
      "\n",
      "it 's dumb , but more importantly , it 's just not \u001b[91mscary\u001b[0m . \n",
      "\n",
      "it 's dumb , but more importantly , it 's just not \u001b[92mpanic\u001b[0m . \n",
      "\n",
      "\n",
      "[Succeeded / Failed / Total] 9 / 0 / 9:  90%|███▌| 9/10 [09:52<01:05, 65.83s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
      "\u001b[91mNegative (99%)\u001b[0m --> \u001b[92mPositive (68%)\u001b[0m\n",
      "\n",
      "schaeffer has to \u001b[91mfind\u001b[0m some hook on which to hang his \u001b[91mpersistently\u001b[0m \u001b[91museless\u001b[0m movies , and it \u001b[91mmight\u001b[0m as \u001b[91mwell\u001b[0m be the resuscitation of the middle-aged character . \n",
      "\n",
      "schaeffer has to \u001b[92mfinding\u001b[0m some hook on which to hang his \u001b[92malways\u001b[0m \u001b[92mcounterintuitive\u001b[0m movies , and it \u001b[92mopportunities\u001b[0m as \u001b[92mperfectly\u001b[0m be the resuscitation of the middle-aged character . \n",
      "\n",
      "\n",
      "[Succeeded / Failed / Total] 10 / 0 / 10: 100%|█| 10/10 [11:37<00:00, 69.77s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+--------+\r\n",
      "| Attack Results                |        |\r\n",
      "+-------------------------------+--------+\r\n",
      "| Number of successful attacks: | 10     |\r\n",
      "| Number of failed attacks:     | 0      |\r\n",
      "| Number of skipped attacks:    | 0      |\r\n",
      "| Original accuracy:            | 100.0% |\r\n",
      "| Accuracy under attack:        | 0.0%   |\r\n",
      "| Attack success rate:          | 100.0% |\r\n",
      "| Average perturbed word %:     | 16.35% |\r\n",
      "| Average num. words per input: | 20.9   |\r\n",
      "| Avg num queries:              | 115.3  |\r\n",
      "+-------------------------------+--------+\r\n",
      "\u001b[34;1mtextattack\u001b[0m: Attack time: 697.6808712482452s\r\n"
     ]
    }
   ],
   "source": [
    "# Choose 'textfooler' as the attack recipe\n",
    "# Choose pre-trained model 'albert-base-v2-sst2'\n",
    "!textattack attack --recipe textfooler --model albert-base-v2-sst2 --num-examples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34;1mtextattack\u001b[0m: WARNING: TextAttack's model training feature is in beta. Please report any issues on our Github page, https://github.com/QData/TextAttack/issues.\n",
      "\u001b[34;1mtextattack\u001b[0m: Writing logs to /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/outputs/training/distilbert-base-uncased-rotten_tomatoes-2021-03-22-12-03-15-551750/log.txt.\n",
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes_movie_review (/Users/tongxue/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/9198dbc50858df8bdb0d5f18ccaf33125800af96ad8434bc8b829918c987ee8a)\n",
      "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mtrain\u001b[0m.\n",
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes_movie_review (/Users/tongxue/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/9198dbc50858df8bdb0d5f18ccaf33125800af96ad8434bc8b829918c987ee8a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes_movie_review (/Users/tongxue/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/9198dbc50858df8bdb0d5f18ccaf33125800af96ad8434bc8b829918c987ee8a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes_movie_review (/Users/tongxue/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/9198dbc50858df8bdb0d5f18ccaf33125800af96ad8434bc8b829918c987ee8a)\n",
      "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
      "\u001b[34;1mtextattack\u001b[0m: Loaded dataset. Found: 2 labels: [0, 1]\n",
      "\u001b[34;1mtextattack\u001b[0m: Loading transformers AutoModelForSequenceClassification: distilbert-base-uncased\n",
      "Downloading: 100%|██████████████████████████████| 442/442 [00:00<00:00, 253kB/s]\n",
      "Downloading: 100%|███████████████████████████| 268M/268M [00:40<00:00, 6.69MB/s]\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading: 100%|███████████████████████████| 232k/232k [00:00<00:00, 1.89MB/s]\n",
      "Downloading: 100%|███████████████████████████| 466k/466k [00:00<00:00, 1.06MB/s]\n",
      "Downloading: 100%|███████████████████████████| 28.0/28.0 [00:00<00:00, 14.6kB/s]\n",
      "\u001b[34;1mtextattack\u001b[0m: Training model across 0 GPUs\n",
      "\u001b[34;1mtextattack\u001b[0m: Wrote original training args to /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/outputs/training/distilbert-base-uncased-rotten_tomatoes-2021-03-22-12-03-15-551750/train_args.json.\n",
      "\u001b[34;1mtextattack\u001b[0m: ***** Running training *****\n",
      "\u001b[34;1mtextattack\u001b[0m: \tNum examples = 8530\n",
      "\u001b[34;1mtextattack\u001b[0m: \tBatch size = 128\n",
      "\u001b[34;1mtextattack\u001b[0m: \tMax sequence length = 64\n",
      "\u001b[34;1mtextattack\u001b[0m: \tNum steps = 198\n",
      "\u001b[34;1mtextattack\u001b[0m: \tNum epochs = 3\n",
      "\u001b[34;1mtextattack\u001b[0m: \tLearning rate = 1e-05\n",
      "Loss 0.6312387684981028: 100%|██████████████████| 67/67 [28:09<00:00, 25.21s/it]\n",
      "\u001b[34;1mtextattack\u001b[0m: Train accuracy: 67.04572098475967%\n",
      "\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 79.54971857410882%\n",
      "\u001b[34;1mtextattack\u001b[0m: Best acc found. Saved model to /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/outputs/training/distilbert-base-uncased-rotten_tomatoes-2021-03-22-12-03-15-551750/.\n",
      "\u001b[34;1mtextattack\u001b[0m: Saved updated args to /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/outputs/training/distilbert-base-uncased-rotten_tomatoes-2021-03-22-12-03-15-551750/train_args.json\n",
      "Loss 0.51884784241368: 100%|████████████████████| 67/67 [27:27<00:00, 24.60s/it]\n",
      "\u001b[34;1mtextattack\u001b[0m: Train accuracy: 82.35638921453693%\n",
      "\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 82.17636022514071%\n",
      "\u001b[34;1mtextattack\u001b[0m: Best acc found. Saved model to /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/outputs/training/distilbert-base-uncased-rotten_tomatoes-2021-03-22-12-03-15-551750/.\n",
      "\u001b[34;1mtextattack\u001b[0m: Saved updated args to /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/outputs/training/distilbert-base-uncased-rotten_tomatoes-2021-03-22-12-03-15-551750/train_args.json\n",
      "Loss 0.4638475488126278: 100%|██████████████████| 67/67 [29:12<00:00, 26.15s/it]\n",
      "\u001b[34;1mtextattack\u001b[0m: Train accuracy: 85.14654161781947%\n",
      "\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 83.02063789868667%\n",
      "\u001b[34;1mtextattack\u001b[0m: Best acc found. Saved model to /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/outputs/training/distilbert-base-uncased-rotten_tomatoes-2021-03-22-12-03-15-551750/.\n",
      "\u001b[34;1mtextattack\u001b[0m: Saved updated args to /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/outputs/training/distilbert-base-uncased-rotten_tomatoes-2021-03-22-12-03-15-551750/train_args.json\n",
      "Epoch: 100%|██████████████████████████████████| 3/3 [1:28:00<00:00, 1760.24s/it]\n",
      "\u001b[34;1mtextattack\u001b[0m: Finished training. Re-loading and evaluating model from disk.\n",
      "\u001b[34;1mtextattack\u001b[0m: Loading transformers AutoModelForSequenceClassification: distilbert-base-uncased\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34;1mtextattack\u001b[0m: Saved model accuracy: 83.02063789868667%\n",
      "\u001b[34;1mtextattack\u001b[0m: Saved tokenizer <textattack.models.tokenizers.auto_tokenizer.AutoTokenizer object at 0x7fb46c987340> to /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/outputs/training/distilbert-base-uncased-rotten_tomatoes-2021-03-22-12-03-15-551750/.\n",
      "\u001b[34;1mtextattack\u001b[0m: Wrote README to /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/outputs/training/distilbert-base-uncased-rotten_tomatoes-2021-03-22-12-03-15-551750/README.md.\n",
      "\u001b[34;1mtextattack\u001b[0m: Wrote final training args to /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/outputs/training/distilbert-base-uncased-rotten_tomatoes-2021-03-22-12-03-15-551750/train_args.json.\n"
     ]
    }
   ],
   "source": [
    "!textattack train --model distilbert-base-uncased --dataset rotten_tomatoes --max-length 64 --epochs 3 --learning-rate 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34;1mtextattack\u001b[0m: Loading transformers AutoModelForSequenceClassification: /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/outputs/training/distilbert-base-uncased-rotten_tomatoes-2021-03-22-12-03-15-551750\n",
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes_movie_review (/Users/tongxue/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/9198dbc50858df8bdb0d5f18ccaf33125800af96ad8434bc8b829918c987ee8a)\n",
      "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
      "\u001b[34;1mtextattack\u001b[0m: Got 1000 predictions.\n",
      "\u001b[34;1mtextattack\u001b[0m: Correct 833/1000 (\u001b[94m83.30%\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "!textattack eval --num-examples 1000 --model /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/outputs/training/distilbert-base-uncased-rotten_tomatoes-2021-03-22-12-03-15-551750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['What I cannot create, I do not understands.'], ['What I notable create, I do not understand.'], ['What I cannot engender, I do not understand.'], ['What I cannot creations, I do not understand.'], ['What I cannot engender, I do not understand.'], ['What I cannot creations, I do not understand.'], ['What I notable create, I do not understand.'], ['Whar I cannot create, I do not understand.'], ['What I significant create, I do not understand.'], ['What I cannot engender, I do not understand.']]\n"
     ]
    }
   ],
   "source": [
    "from textattack.augmentation import EmbeddingAugmenter\n",
    "augmenter = EmbeddingAugmenter()\n",
    "s = 'What I cannot create, I do not understand.'\n",
    "results = []\n",
    "for i in range(10):\n",
    "    results.append(augmenter.augment(s))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
